<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MIL UK</title>
    <link rel="stylesheet" href="styles/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
</head>
<body>
  <header>
    <div class="container">
      <nav>
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="people.html">People</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="events.html">Events</a></li>
            <li><a href="careers.html">Join Us</a></li>
            <li><a href="#contact">Contact</a></li>
          </ul>
        </nav>
    </div>
  </header>

  <main>
    <section id="home" class="hero">
      <div class="lab-title-container">
        <h1>Multimodal Intelligence Lab</h1>
        <img src="assets/images/mmi-lab-logo.jpg" alt="University of Exeter Logo" class="logo">
        <h3>Department of Computer Science, University of Exeter</h3>
      </div>
      <div class="container">
        <p>Welcome to the Multimodal Intelligence Lab, where we explore innovative solutions at the intersection of Artificial Intelligence, Machine Learning, and Multimodal Data Processing. Aligned with the University of Exeter’s 2030 strategy, our research investigates how <strong><u>Multimodal AI</u></strong> and related disciplines can contribute to a greener, healthier, and fairer society. Our core focus is the development of computer vision and machine learning techniques, with applications in healthcare, the environment, and social science.</p>
      </div>
    </section>

    <section id="news" class="news">
      <div class="container">
        <h2>News</h2>
        <div class="news-list" style="overflow-y: scroll; height: 300px;">
          <p>[Jun 2025] Congrats to Ming and the team for a paper, <b>Memory-Augmented SAM2 for Training-Free Surgical Video Segmentation</b>, getting <b>accepted</b> in <a href="https://conferences.miccai.org/2025/en/" target="_blank">MICCAI 2025</a>.</p>

          <p>[Jun 2025]: Congrats to Shuaiyu and the team for the full version of <a href="https://ml-for-rs.github.io/iclr2025/camera_ready/papers/30.pdf" target="_blank">OSDMamba</a> getting <b>accepted</b> in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8859" target="_blank">IEEE Geoscience and Remote Sensing Letters</a>.</p>

          <p>[Apr 2025]: Dr Zeyu Fu has been invited to serve as a <b>Guest Editor</b> for a forthcoming <a href="https://www.mdpi.com/journal/bioengineering/special_issues/H3509E953X" target="_blank">Special Issue in Bioengineering</a>, focused on AI-driven imaging and analysis for biomedical applications. <b>(Deadline: 1 October 2025)</b></p>

          <p>[Mar 2025]: Congrats to Shuaiyu and the team for a paper on Mamba-based oil spill detection getting <b>accepted</b> in <a href="https://ml-for-rs.github.io/iclr2025/" target="_blank">ICLR 2025-ML4RS</a>. (<b>Oral Presentation</b>)</p>

          <p>[Feb 2025]:  <a href="https://adum.fr/as/ed/voirproposition.pl?site=PSaclay&matricule_prop=62141&langue=en" target="_blank">A joint PhD opportunity</a> with the University of Exeter & <a href="https://www.universite-paris-saclay.fr" target="_blank">Université Paris-Saclay.</a> The project is to work on <a href="https://www.linkedin.com/feed/update/urn:li:activity:7300206304449441793/" target="_blank">Generative Multimodal Fusion & Uncertainty Quantification for Environmental Monitoring</a>. Please get in touch with your CV and a research plan before the deadline: 30 Mar 2025. Please get in touch with your CV and a research plan before the deadline: 30 Mar 2025.</p>

          <p>[Jan 2025]:  <a href="https://www.exeter.ac.uk/study/pg-research/funding/phdfunding/epsrc-dla-studentships/important_information_epsrcdla/" target="_blank">PhD Studentships</a> with EPSRC DLA for September 2025 Entry! Join my Multimodal Intelligence Lab to work on a project titled <a href="https://www.exeter.ac.uk/v8media/recruitmentsites/documents/Beyond_Texts-_Harnessing_Multimodal_AI_to_Combat_Online_Harmful_Content_in_Videos_EPSRC_DLA_Project_September_2025_Entry.pdf" target="_blank">"Beyond Texts: Harnessing Multimodal AI to Combat Online Harmful Content in Videos."</a></p>
          
          <p>[Dec 2024]: Congrats to Fu Wang and the team for a paper about evaluating semantic robustness in Bird's Eye View Detection getting <strong>accepted</strong> in <a href="https://aaai.org/conference/aaai/aaai-25/" target="_blank">AAAI 2025</a>.</p>
          
          <p>[Nov 2024]: We're hiring Winter/Summer <strong>Research Interns</strong> (50% FTE) to join our <strong>Multimodal Intelligence Lab</strong>! Work on <strong>multimodal ML</strong>, <strong>video analysis</strong>, <strong>multimedia computing</strong>, and <strong>ML for medical imaging</strong> or <strong>remote sensing</strong>. <u>UK-based & right to work required</u>. Email your CV + research statement to apply.</p>
          
          <p>[Oct 2024]: <strong>Exciting Opportunities</strong> to join our <strong>Multimodal Intelligence Lab</strong> at the <u>University of Exeter: Exeter-CSC PhD Scholarships</u> are open for applications. Please get in touch with your CV and research plans before the deadline: <strong>2 Dec 2024</strong>.</p>

          <p>[Sep 2024]: A paper titled <a href="https://doi.org/10.1016/j.neucom.2024.128673" target="_blank">"Pose-Oriented Scene-Adaptive Matching for Abnormal Event Detection"</a> co-authored with <a href="https://www.ncl.ac.uk/engineering/research/electrical-electronic-engineering/intelligent-sensing-communication/signal-process-ai/" target="_blank">Newcastle University</a> is <strong>accepted</strong> for publication in <a href="https://www.sciencedirect.com/journal/neurocomputing" target="_blank">Neurocomputing</a>.</p>

          <p>[Aug 2024]: A paper titled <a href="https://arxiv.org/abs/2309.15635" target="_blank">"Position and Orientation-Aware One-Shot Learning for Medical Action Recognition from Signal Data"</a> co-authored with <a href="https://www.ncl.ac.uk/engineering/research/electrical-electronic-engineering/intelligent-sensing-communication/signal-process-ai/" target="_blank">Newcastle University</a> is <strong>accepted</strong> for publication in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046" target="_blank">IEEE Transactions on Multimedia</a>.</p>
          
          <p>[Feb 2024]: We are seeking a <a href="https://www.jobs.ac.uk/search/?academicDisciplineFacet[0]=computer-sciences&subDisciplineFacet[0]=artificial-intelligence&salaryBandFacet[0]=up-to-9999&expired-job-redirect=true" target="_blank">Postdoctoral Research Fellow</a> at the University of Exeter (in collaboration with <a href="https://jianbojiao.com" target="_blank">Dr Jianbo Jiao</a> from the University of Birmingham) to work on <strong>multi-modal learning</strong> (visual, text and audio) for <strong>video understanding</strong>.</p>

          <p>[Jan 2024]: A paper titled <a href="https://www.sciencedirect.com/science/article/pii/S0301562924000322" target="_blank">"Automating the Human Action of First-trimester Biometry Measurement from Real-world Freehand Ultrasound"</a> from the <a href="https://eng.ox.ac.uk/pulse/"> PULSE project</a> is accepted for publication in <a href="https://www.sciencedirect.com/journal/ultrasound-in-medicine-and-biology">Ultrasound in Medicine & Biology</a>.</p>
        </div>
      </div>
    </section>

    <section id="contact" class="contact">
      <div class="container">
        <h2>Contact Us</h2>

        <div class="contact-details">
          <p><strong>Email: </strong><a href="mailto:mmi.lab.uk@gmail.com">mmi.lab.uk@gmail.com</a></p>
          <p><strong>Address: </strong>Innovation Centre, Rennes Dr, Exeter, EX4 4RN</p>
        </div>
        
        <div class="map-container">
          <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2525.00149901667!2d-3.5335078232017127!3d50.738461071648544!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x486da4436e4494cb%3A0x1c62c9fa168f33ac!2sInnovation%20Centre%2C%20Rennes%20Dr%2C%20Exeter%20EX4%204RN!5e0!3m2!1sen!2suk!4v1738582419934!5m2!1sen!2suk" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
        </div>
      </div>
    </section>

    <section id="partners">
      <h2>Selected Funders</h2>
      <p>The research works at MIL has gratefully received funding from several distinguished and venerable funders.</p>
      <div class="partners-container">
        <img src="assets/logos/the_alan_turing_institute_logo.jpeg" alt="Alan Turing Institute">
        <img src="assets/logos/exeter.png" alt="University of Exeter">
        <img src="assets/logos/dso_singapore_log.png" alt="DSO National Laboratories">
        <img src="assets/logos/ukri_logo.png" alt="UKRI">
        <!-- <img src="assets/logos/birmingham-uni.jpeg" alt="University of Birmingham"> -->
        <!-- <img src="assets/logos/univ-liverpool.png" alt="University of Liverpool"> -->
      </div>
    </section>
    <section id="partners">
      <h2>Selected Collaborators</h2>
      <p>The lab is fortunate to collaborate with a range of internal and external partners.</p>
      <div class="partners-container">
        <!-- <img src="assets/logos/the_alan_turing_institute_logo.jpeg" alt="Alan Turing Institute"> -->
        <!-- <img src="assets/logos/exeter.png" alt="University of Exeter"> -->
        <img src="assets/logos/newcastle-uni.png" alt="Newcastle University">
        <img src="assets/logos/birmingham-uni.jpeg" alt="University of Birmingham">
        <img src="assets/logos/univ-liverpool.png" alt="University of Liverpool">
      </div>
    </section>  
  </main>

  <footer>
    <div class="container">
      <div class="social-icons">
        <a href="mailto:mmi.lab.uk@gmail.com" target="_blank" aria-label="Email">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        <a href="https://github.com/mmilabuk" target="_blank" aria-label="GitHub">
          <i class="fab fa-github"></i>
        </a>
        <a href="https://x.com/mmi_lab_uk" target="_blank" aria-label="X">
          <i class="fab fa-x-twitter"></i>
        </a>
        <a href="https://www.linkedin.com/in/multimodal-intelligence-lab-uk-92a590349/" target="_blank" aria-label="LinkedIn">
          <i class="fab fa-linkedin-in"></i>
        </a>
        <a href="https://www.youtube.com/@mmi_lab_uk" target="_blank" aria-label="YouTube">
          <i class="fab fa-youtube"></i>
        </a>
      </div>
      <p>&copy; 2025 Multimodal Intelligence Lab, University of Exeter. All rights reserved.</p>
    </div>
  </footer>
</body>
</html>
